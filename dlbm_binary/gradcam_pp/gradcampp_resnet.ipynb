{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Copyright 2023 by Micha≈Ç Stolarz <michal.stolarz@h-brs.de>\n",
    "\n",
    "    This file is part of dlbm_binary.\n",
    "    It is used for obtaining Grad-CAM++ heatmaps for ResNet50 model.\n",
    "\n",
    "    dlbm_binary is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU Affero General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "    dlbm_binary is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU Affero General Public License for more details.\n",
    "    You should have received a copy of the GNU Affero General Public License\n",
    "    along with dlbm_binary. If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from training.pretrained import DeepClassifier\n",
    "from config import config_resnet\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from utils.data_loader import InteractionDataset\n",
    "from torchvision.models import ResNet50_Weights as weights\n",
    "from torchvision.transforms import Resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DeepClassifier(cfg=config_resnet, input_state_size=1, rgb=True, validation=True)\n",
    "model = agent.model\n",
    "\n",
    "target_layers = [model.layer4[-1].relu]\n",
    "model.layer4[-1]\n",
    "\n",
    "preprocess = weights.IMAGENET1K_V1.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit = 30\n",
    "loop_index = 0\n",
    "\n",
    "for dataset_id in range(1, 4):\n",
    "\n",
    "    if dataset_id == 2:\n",
    "        test = InteractionDataset(path='/home/michal/thesis/test_frames', n_frames_used=1, rgb=True, standardization=False)\n",
    "    elif dataset_id == 3:\n",
    "        test = InteractionDataset(path='/home/michal/thesis/white_background_frames', n_frames_used=1, rgb=True, standardization=False)\n",
    "\n",
    "    if dataset_id in [2, 3]:\n",
    "        testloader = torch.utils.data.DataLoader(test,\n",
    "                                             batch_size=1)\n",
    "\n",
    "    if dataset_id == 1:\n",
    "        testloader = agent.testloader\n",
    "\n",
    "    img_id = 0\n",
    "\n",
    "    for image, label in testloader:\n",
    "        input_tensor = image.to('cuda')\n",
    "        img_path = testloader.dataset.img_path.split('/')[-1]\n",
    "\n",
    "        if dataset_id == 1:\n",
    "            if img_path not in ['x_6XTLNK55_b11_14_6.jpg', 'x_5J7PWO3G_b8_16_3.jpg', 'x_3G4MPE2W_randomised_b2_2_2.jpg', 'x_Q4GTE6L4_b3_14_1.jpg']:\n",
    "                continue\n",
    "\n",
    "        if dataset_id == 2:\n",
    "            if img_path not in ['6XTLNK55_b1_14_6.jpg', '5J7PWO3G_b0_16_3.jpg', '3G4MPE2W_randomised_b1_2_2.jpg', 'Q4GTE6L4_b4_14_1.jpg']:\n",
    "                continue\n",
    "\n",
    "        if dataset_id == 3:\n",
    "            if img_path not in ['6XTLNK55_w_14_6.jpg', '5J7PWO3G_w_16_3.jpg', '3G4MPE2W_randomised_w_2_2.jpg', 'Q4GTE6L4_w_14_1.jpg']:\n",
    "                continue\n",
    "\n",
    "        pred = model(preprocess(input_tensor))\n",
    "        pred1 = pred.argmax(dim=1)\n",
    "        label_num = label.tolist()[0]\n",
    "        label_pred_num = pred1.tolist()[0]\n",
    "\n",
    "        if label_pred_num != label_num:\n",
    "            continue\n",
    "\n",
    "        print(img_path)\n",
    "        input_tensor = image\n",
    "        cam = GradCAMPlusPlus(model=model, target_layers=target_layers, use_cuda=True)\n",
    "        targets = [ClassifierOutputTarget(int(label))]\n",
    "\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                            targets=targets)\n",
    "\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        gray_image = np.array(image[0][0])\n",
    "        stacked_gray_img = np.stack((gray_image,) * 3, axis=-1)\n",
    "        #img = np.zeros([198, 198, 3], dtype=np.float32)\n",
    "\n",
    "        visualization = show_cam_on_image(stacked_gray_img, grayscale_cam, use_rgb = True)\n",
    "        plt.imshow(visualization)\n",
    "        plt.show()\n",
    "        print(f\"Label: {label.tolist()[0]} \\n\"\n",
    "              f\"Predicted: {pred1.tolist()[0]}\")\n",
    "        cv2.imwrite('data_' + str(dataset_id) + '_img_' + str(img_id) + '.jpg', cv2.cvtColor(visualization, cv2.COLOR_BGR2RGB))\n",
    "        img_id+=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
